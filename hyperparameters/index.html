<html lang="en">
	</head>
		<meta charset="utf-8">
		<meta name="description" content="Munachiso Nwadike's research page">
		<meta name="author" content="Munachiso Nwadike">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		
		<link rel="preconnect" href="https://fonts.gstatic.com">
		<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;700&family=Open+Sans&display=swap" rel="stylesheet">
		<style>   
			.title-div { 
 				float: top;     
				font-family: 'Montserrat';
				font-size: 40px;
				background-color: white;   
				border-bottom: 0px solid black;  
				width: 1200px;
				margin: auto;
				text-align: center;
			} 
			.section-div { 
				float: center; 
				width: 710px;
				margin: auto;
			} 
			.matplotlib-div { 
				float: center; 
				width: 900px;
				margin: auto;
			}  
			p {
				font-family: 'Open Sans';
				font-size: 16px;
				text-align: justify;
			} 
			img {
				max-width:100%;
			} 
		</style>
		<script type="text/x-mathjax-config">
		    MathJax.Hub.Config({
		      tex2jax: {
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			inlineMath: [['$','$']]
		      }
		    });
		</script>
		<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> 
 		<title> Hyperparameter Tuning Project Page </title>
	</head>
    
	<body>
		<div class = "title-div" >
			<br><br> 
			<b>Bayesian Optimisation <br> for Efficient ML Pipeline Hyperparameter Tuning <br> Under a Cost Budget </b>

		</div>
		<div class = "title-div"  style="font-family:'Montserrat';font-size:20px;color:#209CEE;" >
			<br>
			<b>
			<a style="color:#209CEE;" href="https://munachisonwadike.github.io/">Munachiso S. Nwadike</a>,
			Navish Kumar, 
			Kirill Vishniakov,  
			<a style="color:#209CEE;" href="https://willieneis.github.io/">Willie Neiswanger</a>,
			<a style="color:#209CEE;" href="https://www.andrew.cmu.edu/user/kunz1/index.html">Kun Zhang</a>,
			<a style="color:#209CEE;" href="https://sites.google.com/site/hoqirong/home">Qirong Ho</a>,
			<a style="color:#209CEE;" href="http://www.cs.cmu.edu/~epxing/">Eric Xing</a>
			</b>
		</div>
		<div class = "title-div"  style="font-family: 'Montserrat'; font-size: 30px;" >
			</br>
			<a href="https://munachisonwadike.github.io/"> 
			<button style="background-color:#363636;border-color:#363636;color:white;font-size: 25px;padding: 5px 10px;border-radius: 12px;">üìù Paper</button> 
			</a>
		</div> 

		<div class = "title-div"  style="font-family: 'Montserrat'; font-size: 16px;color:#209CEE" >
			<br>
			<b>In Publication, Coming Soon.</b>
		</div> 

		<div class = "title-div"  style="font-family: 'Montserrat'; font-size: 18px;color:#4A4A4A;width:800px" >
			<br><br><br>
			<b>Key Words: <span style="color:#38761D">Bayesian </span>Optimisation, 
				<span style="color:#38761D">Pipelines</span> setting in <span style="color:#38761D">ML</span>, <span style="color:#38761D">Learned Cost</span>, <span style="color:#38761D"> Memoisation</span>, <span style="color:#38761D">Cumulative</span> Cost.</b>
			<br>
			<br>
			<br>
			<br> 
		</div> 
		
		<div class = "section-div"  style="float:center;width:850;">  
			<center><p style= "font-family: 'Montserrat'; font-size: 40px; text-align: center;">Problem Statement</p> <center>
			<ol type="a" >
				<li><p> In ML we often need to "stitch" difference multiple components into a <b>pipeline</b>. </p> </li>
				<li><p> Can we simultaneously and automatically tune hyperparameters of these pieces in an end-to-end fashion? </p> </li>
				<li><p> Is it possible to tune for different types of objectives (e.g inference speed, latency, compute cost, memory usage, ML accuracy)?  </p> </li>
			</ol>
		</div>

		<div class="section-div" style="float:center;width:1000;height:700 ">
			<div class = "section-div" style="float:left;width:500;height:700"> 
				<center><p style="font-family: 'Montserrat'; font-size: 40px; text-align: center;">Overview</p> </center>
				<p>Bayesian optimization (BO) is often used for 
					hyperparameter tuning, due to its ability to optimize black-box functions efficiently
					Efficiency is often measured in terms of number of iterations required for convergence. 
					However, at each iteration of the BO algorithm, different
					hyperparameters may incur different costs (i.e. time units required to
					perform a query). Thus, measuring covergence speed in terms of number of iterations,
					may not be representative of the true cost incurred by a given BO acquisition function. Furthermore,
					most BO acqusition functions are often tailored to tune the hyperparameters of the ML model alone. For example, when tuning a random forest classifier model, assume that we have access to an oracle, which tells us that the ideal <i>max depth</i> hyperparameter is 100. We would like our BO algorithm to achieve a tradeoff between a small max depth hyperparameter (say 10), which may result in a low accuracy, at a low latency, and a high max depth (say 10000), which could potentially result in a high accuracy, at high latency. However, this random forest classifier may depend on a preprocessing step such as TF-IDF vectorisation, which also bears tunable hyperparameters. Indeed, ML models are often dependent on one or more preprocessing and postprocessing steps, as part of an <b><i>ML pipeline</b></i> (see visualisation on the right). We propose a novel BO acquisition function to ML pipeline hyparameter tuning, and demonstrate its experimental cost-efficiency.
					</p>
			</div>
			<div class = "section-div" style="float:right;width:450;height:700">  
				<center><p style="font-family: 'Montserrat'; font-size: 40px; text-align: center;">Example</p> </center>  
				<center><img src="problem_visualisation.PNG" alt="problem Visualisation" style="margin-top:10px;max-width:100%;">  <center>
				<br>
				<p style="font-size:14px;width:430;"> Visualisation of an ML pipeline for the object detection task. 
				Here, the preprocessing step may include image resizing and deblurring. The 
				resize width/height, and gaussian kernel represent preprocessing stage hyperparameters. Postprocessing hyperparameters may include NMS threshold.</p>
			</div> 
		</div>	

		<div class = "section-div"  style="float:center;width:850;">  

				<center><p style= "font-family: 'Montserrat'; font-size: 40px; text-align: center;">Heterogenous Cost</p> <center>
				<!-- <center><img src="memoisation.PNG" alt="Memoisation" style="max-width:85%;"> </center> -->

				<p>	A multi-stage ML pipeline will have multiple cost subspaces. 
					Consider, for example, the below 3-stage pipeline with 2 hyperparameters per stage. 
					$[x_1, x_2]$, $[x_3, x_4]$, and $[x_5, x_6]$ represent the hyperparameters for stage 1, 2 and 3 respectively.
					Meanwhile, the cost functions for the 3 stages are represented by $|\sin(x_1^2)+\cos(x_1+x_2)|$, $|\sin(x_3)\cdot \cos(10+x_4)|$,
					and $|\cos(x_5/x_6) \cdot \sin(4-x_5x_6)\cdot \sin(0.5\cdot x_5) |$ respectively. If we consider the heatmaps of cost values for each stage, wherein the hyperparameter values are restricted to
					$[-5,5]$, the cost function spaces will appears as shown on the right hand side of the below image. </p>

					<center><img src="cost_landscape.PNG" alt="Cost" style="margin-top:10px;max-width:70%;"> </center>

				<p>
					The overall cost function of the pipeline is therefore $|\sin(x_1^2)+\cos(x_1+x_2)|$ + $|\sin(x_3)\cdot \cos(10+x_4)|$ + $|\cos(x_5/x_6) \cdot \sin(4-x_5x_6)\cdot \sin(0.5\cdot x_5) |$. It is visualised in the top left corner of the above image.  Note that while this is a function in $\mathbb{R}^6$, we 
					provide a 2-dimensional visualisation  of the function upon the 6-dimensional domain. The addition of the costs 
					is the direct result of composition of pipelines stages. <br><br>

					Our goals, with our novel BO algorithm for ML pipelines, is to is to minimise total cost over all pipeline stages, while optimising the objective function. In this case, the objective function is defined as $\mathrm{obj}(x) = |x_1^2 + x_2^2 + x_3^2 + x_4^2 + x_5^2 + x_6|$, 
					also represented in 2D.
 					Observe that the high cost and low cost regions occur in different parts of the space from the high and low objective function regions. 


					 </p>

		</div>

		<div class = "section-div"  style="float:center;width:850;"> 
			<br><br><br>
			<center><p style= "font-family: 'Montserrat'; font-size: 40px; text-align: center;">Methodology</p> <center>
			

			<!-- <p>We usually think of just the model stage, as visualised in the image above. Now let us think about
			individual hyperparameter, as in the image below: what do you see? The answer is ... </p>
			<center><img src="3_stage_ppln.PNG" alt="Cost" style="max-width:53%;" ></center> --> 

			<p>When performing hyperparameter search in an ML pipeline
				setting, we can cache hyperparameter combinations from earlier stages of a pipeline, once
				queried, to be reused with hyperparameter combinations of latter stages in a pipeline, for
				a more effecient search. This cache-and-reuse is referred to as memoisation. For example, to the left of the image below, we have a 3-stage pipeline where $x_1=1.2$, $x_2=4.0$, and $x_3=1.0$, 
				are the hyperparameters for 3 respective ML pipeline stages. 
				The costs associated with the hyperparameter is shown in orange, e.g the cost for the stage 1 is 5.1. </p>

			<center><img src="memoisation.PNG" alt="Memoisation" style="max-width:80%;"> </center>
			<p> To the right of the image below, we have a "prefix pool", resulting from the queried hyperparameter combination
				This prefix pool has two entries: the first is a hyperparameter combination where $x_1=1.2$ was stored from a prior run, and the second is one where $x_1=1.2$ and  $x_2=4.0$ were both stored. Our proposed EEIPU acquisition function 
				would discount costs from prior queried hyperparameters in both cases, when calculating expected improvement per unit costs. 

			</p>

			<center><img src="algorithm_eeipu.PNG" alt="eeipu_mem" style="max-width:70%;"> </center>
			<p> We discount the cost of non-memoised stages within our acqusition function as above. Expected inverse cost excludes 
			costs from stages which have been memoised. $\delta$ is a threshold variables that tells us the earliest non-memoised 
			stage from which to begin considering costs (i.e where we end our discounting). Discounting memoised costs in this way may result in over-biasing towards previously queried points. Our research finds the needed balance between exploration and exploitation.  

			<br><br>
			While we have analytical, closed form expressions for the cost functions for the above pipeline, this is 
				often not the case for real world piplines. For example, one usually does not know the relationship between hyperparmaeters 
				of a computer vision pipeline and pipeline latency/speed. As a result, we model cost at each pipeline stage
				as a Guassian process, and log latency measurements for queried hyperparameter combinations, to use in iteratively modeling the stagewise costs.
				 </p>
		</div>
		
		<div class = "section-div" style="float:center;width:1050;"> 
			<br><br> 	
			<center><p style="font-family: 'Montserrat'; font-size: 40px; text-align: center;">Experiments</p> </center>  
		</div>
		<div class = "section-div" style="float:center;width:850;">  
			<p>BO algorithms are often tested on a range of synthetic functions designed to assess convergence.
			Compositions of these functions can be use to form a pipeline. Below are results for 2-stage pipeline where the 
			cost objective for each stage is a 2-dimensional negative Branin function, while the objective function is a sum of logistic functions. The overall objective, is given by $-$Branin$(x_1,x_2)$ $-$Branin$(x_3,x_4)$. Stagewise costs are $-\texttt{logistic}(x_1) -\texttt{logistic}(x_2)$ for stage 1, and $-\texttt{logistic}(x_3) + (1/x_4)$ for stage 2.</p>
		</div>
		<div class = "section-div" style="float:center;width:1050;"> 
			<!-- <center><img src="norm3d_2.png" alt="Cost" style="max-width:95%;" ></center>  -->
			<center><img src="branin4d.png" alt="Cost" style="max-width:95%;" ></center> 	
		</div>
		<div class = "section-div" style="float:center;width:850;"> 
			<br><br>
			<p>Our EEIPU algorithm If indeed our algorithm worked, we would expect to see that our EEIPU function would perform identically to EIPU. This is what we observe from our initial experiments, as can be seen from green line sits in between the red and the yello in the second plot from the left, above. Regular expected improvement (EI), is represented by the red line. EI, which does not factor in cost at all, naturally performs well in terms of the traditional number of iterations required for convergence, but underperforms EEIPU and EIPU when cumulative cost is considered EIPU has the advantage of having an oracle available to it, which specifies the true cost at each point in the hyperparameter space. This is not realistic in real-world scenarios, where one does  not know the cost of a hyperparameter combination until after it has been evaluated - an expensive operation. It is thus impressive that without access to an oracle as such, EEIPU is able to compete with EIPU in terms of objective value delta per cumulative cost incurred.</p>
			<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
		</div> 
	</body>
</html>
