<html lang="en">
	</head>
		<meta charset="utf-8">
		<meta name="description" content="Munachiso Nwadike's research page">
		<meta name="author" content="Munachiso Nwadike">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		
		<link rel="preconnect" href="https://fonts.gstatic.com">
		<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;700&family=Open+Sans&display=swap" rel="stylesheet">
		<style>   
			.title-div { 
 				float: top;     
				font-family: 'Montserrat';
				font-size: 40px;
				background-color: white;   
				border-bottom: 0px solid black;  
				width: 900px;
				margin: auto;
				text-align: center;
			} 
			.section-title-div { 
				position: relative;
				float: top;  
				height: auto; 
				width: auto;
				margin: auto; 
				font-family: 'Montserrat';
				font-size: 29px;
				text-align: center;
			} 
			
			.section-div { 
				float: center; 
				width: 710px;
				margin: auto;
			} 
			.matplotlib-div { 
				float: center; 
				width: 900px;
				margin: auto;
			} 
			.caption-div { 
				float: center; 
				width: 710px;
				margin: auto;
				font-family: 'Open Sans';
				font-size: 14px;
			} 
			p {
				font-family: 'Open Sans';
				font-size: 18px;
				text-align: justify;
			} 
			img {
				max-width:100%;
			} 
		</style>
		<script type="text/x-mathjax-config">
		    MathJax.Hub.Config({
		      tex2jax: {
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			inlineMath: [['$','$']]
		      }
		    });
		</script>
		<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> 
 		<title> Hyperparameter Tuning Project Page </title>
	</head>
    
	<body>
		<div class = "title-div" >
			<br><br> 
			<b>Bayesian Optimisation <br> for Efficient ML Pipeline Hyperparameter Tuning <br> Under a Cost Budget </b>
		</div>
		<div class = "section-div" > 
			<br>
			<br>
			<br>
			<center><img src="cost_landscape.PNG" alt="Cost" style="marin-top:10px;max-width:80%;"> </center>
			<div class = "caption-div"> 
				<br>
				$$\frac{a}{b}$$When $a \ne 0$, there are two solutions to \(ax^2 + bx + c = 0\) and they are
				$$x = {-b \pm \sqrt{b^2-4ac} \over 2a}.$$ 
			</div>
		</div>
		</div>
		<div class = "section-title-div"> 
			<br>
			<br>
			<br>
			<b>Abstract</b>
			
		</div>
		<div class = "section-div" > 
			<br><br>
			<p>Bayesian optimization (BO) offers a simple mechanism of optimising functions whose
				closed form expression may not be known, within a limited iteration budget. This is
				particularly useful in the problem of hyperparameter tuning. At each iteration, different
				regions in a search space of inputs may incur different costs, i.e time units required to
				perform a query. The function which assigns a cost to each point in the input space may
				also not be known. Much of the BO literature, however, tends to focus on the number of
				iterations incurred for convergence, rather than the total costs incurred. Furthermore, little
				research has been done on specified formulations of BO which are needed for ML pipeline
				hyperparameter tuning. In the ML pipeline setting, we wish to tune hyperparameters of
				not just a machine learning model, but also of any additional steps involved in the overall
				artificial intelligence system. For example, in computer vision, we may be concerned with
				image preprocessing and output postprocessing steps, and the hyperparameters involved
				in these stages our pipeline. When performing hyperparameter search in an ML pipeline
				setting, we can cache hyperparameter combinations from earlier stages of a pipeline, once
				queried, to be reused with hyperparameter combinations of latter stages in a pipeline, for
				a more effecient search. This cache-and-reuse is referred to as memoisation. We propose
				a new acquisition function for BO, referred to as EEIPU, that is uniquely suited to the
				pipeline setting. Furthermore, we explore techniques regarding the combination of EEIPU,
				with memoised hyperparameter search. One key feature of EEIPU is that we design it to
				work in a scenario whereby the closed form of the cost function at each pipeline stage
				is unknown. In addition, we devote extensive resources to designing ML pipeline tuning
				systems, which can work hand-in-hand with our acquisition function. These systems are
				built towards allowing our acquisition function to be deployed in real-world industry or
				research use cases, for entire-pipeline hyperparameter tuning. We study the experimental
				behaviour of EEIPU, and compare it with related acquisition functions in the literature,
				to better understand its performance, and propose future research directions</p>
		</div>
		<div class = "section-title-div"> 
			<br>
			<br>
			<br>
			<b>Methodology</b> 
		</div>		 
		<div class = "section-div" > 
			<br><br>
			<center><img src="3_stage_ppln.PNG" alt="Cost" style="max-width:50%;" ></center> 
			<center><img src="memoisation.PNG" alt="Memoisation" style="max-width:85%;"> </center>
		</div> 
		<div class = "section-title-div"> 
			<br>
			<br>
			<br>
			<b>Experiments</b> 
			<br>
		</div>	
		<div class = "matplotlib-div" > 
			<br><br>
			<center><img src="norm3d_2.png" alt="Cost" style="max-width:100%;" ></center> 
			<center><img src="branin4d.png" alt="Cost" style="max-width:100%;" ></center> 
			<br><br><br><br><br><br><br><br>
		</div> 
	</body>
</html>
